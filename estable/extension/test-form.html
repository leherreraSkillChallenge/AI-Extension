<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Formulario de Prueba - Asistente IA</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 600px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .form-container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .form-group {
            margin-bottom: 20px;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
            color: #333;
        }
        input, textarea, select {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 5px;
            font-size: 16px;
            transition: border-color 0.3s;
        }
        input:focus, textarea:focus, select:focus {
            border-color: #4CAF50;
            outline: none;
        }
        button {
            background: #4CAF50;
            color: white;
            padding: 12px 30px;
            border: none;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            transition: background 0.3s;
        }
        button:hover {
            background: #45a049;
        }
        .instructions {
            background: #e3f2fd;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
            border-left: 4px solid #2196F3;
        }
        .command-examples {
            background: #f3e5f5;
            padding: 15px;
            border-radius: 5px;
            margin-top: 20px;
            border-left: 4px solid #9c27b0;
        }
        .command-examples h3 {
            margin-top: 0;
            color: #7b1fa2;
        }
        .command-examples ul {
            margin: 10px 0;
        }
        .command-examples li {
            margin: 5px 0;
            font-family: monospace;
            background: rgba(156, 39, 176, 0.1);
            padding: 3px 6px;
            border-radius: 3px;
        }
        .tts-section {
            background: #e8f5e8;
            padding: 20px;
            border-radius: 5px;
            margin-top: 20px;
            border-left: 4px solid #4CAF50;
        }
        .tts-controls {
            display: flex;
            gap: 10px;
            align-items: center;
            margin-top: 15px;
        }
        .tts-controls button {
            padding: 8px 16px;
            font-size: 14px;
        }
        .status-indicator {
            padding: 5px 10px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: bold;
        }
        .status-disconnected { background: #ffcdd2; color: #c62828; }
        .status-connecting { background: #fff3e0; color: #ef6c00; }
        .status-connected { background: #c8e6c9; color: #2e7d32; }
        .status-playing { background: #bbdefb; color: #1565c0; }
    </style>
</head>
<body>
    <div class="form-container">
        <h1>üé§ Formulario de Prueba - Asistente IA</h1>
        
        <div class="instructions">
            <h3>üìã Instrucciones:</h3>
            <p>1. Activa el asistente desde el widget flotante</p>
            <p>2. Usa comandos de voz para llenar el formulario</p>
            <p>3. Prueba tanto comandos de formulario como conversaci√≥n con IA</p>
            <p>4. <strong>Para Texto a Voz:</strong> Configura tu API key de ElevenLabs en el c√≥digo</p>
        </div>

        <form id="testForm">
            <div class="form-group">
                <label for="nombre">Nombre completo:</label>
                <input type="text" id="nombre" name="nombre" placeholder="Escribe tu nombre completo">
            </div>

            <div class="form-group">
                <label for="email">Correo electr√≥nico:</label>
                <input type="email" id="email" name="email" placeholder="tu@email.com">
            </div>

            <div class="form-group">
                <label for="telefono">Tel√©fono:</label>
                <input type="tel" id="telefono" name="telefono" placeholder="123456789">
            </div>

            <div class="form-group">
                <label for="pais">Pa√≠s:</label>
                <select id="pais" name="pais">
                    <option value="">Selecciona un pa√≠s</option>
                    <option value="es">Espa√±a</option>
                    <option value="co">Colombia</option>
                    <option value="mx">M√©xico</option>
                    <option value="ar">Argentina</option>
                    <option value="pe">Per√∫</option>
                    <option value="cl">Chile</option>
                </select>
            </div>

            <div class="form-group">
                <label for="direccion">Direcci√≥n:</label>
                <textarea id="direccion" name="direccion" rows="3" placeholder="Tu direcci√≥n completa"></textarea>
            </div>

            <div class="form-group">
                <label for="codigo">C√≥digo de seguridad:</label>
                <input type="text" id="codigo" name="codigo" placeholder="qaz123456.*">
            </div>

            <button type="submit">Enviar formulario</button>
        </form>

        <!-- Secci√≥n de Texto a Voz -->
        <div class="tts-section">
            <h3>üéµ Prueba de Texto a Voz (ElevenLabs)</h3>
            <div class="form-group">
                <label for="ttsText">Texto para convertir a voz:</label>
                <textarea id="ttsText" name="ttsText" rows="3" placeholder="Escribe aqu√≠ el texto que quieres convertir a voz...">Hola, este es un ejemplo de streaming de texto a voz usando ElevenLabs WebSocket.</textarea>
            </div>
            
            <div class="tts-controls">
                <button type="button" id="connectBtn">Conectar WebSocket</button>
                <button type="button" id="speakBtn" disabled>Hablar (WebSocket)</button>
                <button type="button" id="stopBtn" disabled>Parar</button>
                <button type="button" id="testAudioBtn">üîä Test Audio</button>
                <button type="button" id="restApiBtn">üéµ Probar API REST</button>
                <button type="button" id="testAIBtn">ü§ñ Probar Respuesta AI</button>
                <button type="button" id="downloadDebugBtn" disabled>üíæ Descargar Audio Debug</button>
                <span id="statusIndicator" class="status-indicator status-disconnected">Desconectado</span>
            </div>
            
            <div style="margin-top: 10px;">
                <label for="volumeControl">Volumen: </label>
                <input type="range" id="volumeControl" min="0" max="1" step="0.1" value="1" style="width: 100px;">
                <span id="volumeValue">100%</span>
            </div>
            
            <div style="margin-top: 10px;">
                <small><strong>Nota:</strong> Necesitas una API key v√°lida de ElevenLabs para usar esta funcionalidad.</small>
            </div>
        </div>

        <div class="command-examples">
            <h3>üéØ Ejemplos de Comandos de Formulario:</h3>
            <ul>
                <li>"escribe Juan P√©rez Garc√≠a"</li>
                <li>"agrega juan punto p√©rez arroba gmail punto com"</li>
                <li>"pon 555 123 4567"</li>
                <li>"selecciona Espa√±a"</li>
                <li>"siguiente campo"</li>
                <li>"modifica Mar√≠a Gonz√°lez"</li>
                <li>"elimina espacios"</li>
                <li>"enviar formulario"</li>
            </ul>
            
            <h3>ü§ñ Ejemplos de Conversaci√≥n con IA:</h3>
            <ul>
                <li>"¬øQu√© ves en esta p√°gina?"</li>
                <li>"Expl√≠came c√≥mo funciona este formulario"</li>
                <li>"¬øQu√© informaci√≥n necesito aqu√≠?"</li>
                <li>"Ay√∫dame a completar esto"</li>
            </ul>
        </div>
    </div>

    <script>
        // Prevenir env√≠o real del formulario para pruebas
        document.getElementById('testForm').addEventListener('submit', function(e) {
            e.preventDefault();
            alert('¬°Formulario enviado correctamente! (Modo prueba)');
        });
        
        // Mostrar valores cuando cambien
        document.querySelectorAll('input, textarea, select').forEach(field => {
            field.addEventListener('change', function() {
                console.log(`Campo ${this.name}: "${this.value}"`);
            });
        });

        // ===== FUNCIONALIDAD ELEVENLABS WEBSOCKET =====
        
        // Configuraci√≥n ElevenLabs
        const VOICE_ID = "pNInz6obpgDQGcFmaJgB"; // Adam voice (p√∫blico)
        const API_KEY = "sk_b1f79fd76fc020e5721f94494f741e0df21a629bfb30646e"; // Tu API key real
        
        let ws = null;
        let audioContext = null;
        let audioBuffer = null;
        let currentSource = null;
        let lastAudioData = null; // Para debug
        let currentVolume = 1.0;
        
        // Elementos del DOM
        const connectBtn = document.getElementById('connectBtn');
        const speakBtn = document.getElementById('speakBtn');
        const stopBtn = document.getElementById('stopBtn');
        const testAudioBtn = document.getElementById('testAudioBtn');
        const restApiBtn = document.getElementById('restApiBtn');
        const testAIBtn = document.getElementById('testAIBtn');
        const downloadDebugBtn = document.getElementById('downloadDebugBtn');
        const statusIndicator = document.getElementById('statusIndicator');
        const ttsText = document.getElementById('ttsText');
        const volumeControl = document.getElementById('volumeControl');
        const volumeValue = document.getElementById('volumeValue');
        
        // Inicializar contexto de audio
        async function initAudioContext() {
            try {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                console.log('AudioContext estado:', audioContext.state);
                return true;
            } catch (error) {
                console.error('Error inicializando AudioContext:', error);
                return false;
            }
        }
        
        // Funci√≥n de prueba de audio
        async function testAudio() {
            try {
                await initAudioContext();
                
                // Crear un tono de prueba
                const oscillator = audioContext.createOscillator();
                const gainNode = audioContext.createGain();
                
                oscillator.connect(gainNode);
                gainNode.connect(audioContext.destination);
                
                oscillator.frequency.setValueAtTime(440, audioContext.currentTime); // A4
                gainNode.gain.setValueAtTime(0.1, audioContext.currentTime);
                gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.5);
                
                oscillator.start(audioContext.currentTime);
                oscillator.stop(audioContext.currentTime + 0.5);
                
                alert('Si escuchaste un pitido, el audio funciona correctamente');
                
            } catch (error) {
                console.error('Error en test de audio:', error);
                alert('Error en el test de audio: ' + error.message);
            }
        }
        
        // Funci√≥n para limpiar texto antes de enviar a TTS
        function cleanTextForTTS(text) {
            if (!text) return '';
            
            return text
                // Eliminar saltos de l√≠nea escapados
                .replace(/\\n/g, ' ')
                .replace(/\\r/g, ' ')
                .replace(/\\t/g, ' ')
                // Eliminar saltos de l√≠nea reales
                .replace(/\n/g, ' ')
                .replace(/\r/g, ' ')
                .replace(/\t/g, ' ')
                // Eliminar m√∫ltiples espacios
                .replace(/\s+/g, ' ')
                // Eliminar caracteres especiales que pueden causar problemas
                .replace(/[^\w\s.,!?;:()\-√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú]/g, '')
                // Limpiar espacios al inicio y final
                .trim();
        }
        
        // Funci√≥n para procesar respuesta de AI y enviar a TTS
        function processAIResponse(aiResponse) {
            let textToSpeak = '';
            
            if (typeof aiResponse === 'string') {
                // Si es string directo
                textToSpeak = aiResponse;
            } else if (aiResponse && aiResponse.result) {
                // Si tiene formato { "result": "texto..." }
                textToSpeak = aiResponse.result;
            } else if (aiResponse && aiResponse.text) {
                // Si tiene formato { "text": "texto..." }
                textToSpeak = aiResponse.text;
            } else {
                console.warn('‚ö†Ô∏è Formato de respuesta AI no reconocido:', aiResponse);
                return;
            }
            
            // Limpiar el texto
            const cleanedText = cleanTextForTTS(textToSpeak);
            console.log('üßπ Texto original:', textToSpeak);
            console.log('‚ú® Texto limpio:', cleanedText);
            
            if (cleanedText.length > 0) {
                // Actualizar el textarea con el texto limpio
                ttsText.value = cleanedText;
                
                // Usar API REST autom√°ticamente (m√°s confiable)
                useRestAPI();
            } else {
                console.warn('‚ö†Ô∏è Texto vac√≠o despu√©s de limpiar');
                alert('El texto est√° vac√≠o despu√©s de limpiarlo');
            }
        }
        
        // Funci√≥n para usar API REST de ElevenLabs (m√°s simple y confiable)
        async function useRestAPI() {
            console.log('üåê Intentando API REST de ElevenLabs...');
            updateStatus('connecting', 'Conectando a API REST...');
            
            try {
                let text = ttsText.value.trim();
                if (!text) {
                    alert('Por favor, escribe algo de texto');
                    updateStatus('disconnected', 'Desconectado');
                    return;
                }
                
                // Limpiar el texto antes de enviar
                text = cleanTextForTTS(text);
                console.log('üìù Texto limpio para TTS:', text);
                
                const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`, {
                    method: 'POST',
                    headers: {
                        'Accept': 'audio/mpeg',
                        'Content-Type': 'application/json',
                        'xi-api-key': API_KEY
                    },
                    body: JSON.stringify({
                        text: text,
                        model_id: "eleven_multilingual_v2",
                        voice_settings: {
                            stability: 0.5,
                            similarity_boost: 0.5,
                            style: 0.0,
                            use_speaker_boost: true
                        }
                    })
                });
                
                console.log('üì° Respuesta API:', response.status, response.statusText);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`API Error ${response.status}: ${errorText}`);
                }
                
                const audioData = await response.arrayBuffer();
                console.log('üéµ Audio recibido, tama√±o:', audioData.byteLength);
                
                updateStatus('connected', 'Audio recibido');
                lastAudioData = audioData;
                
                // Reproducir el audio
                await playAudioChunk(audioData);
                
            } catch (error) {
                console.error('‚ùå Error en API REST:', error);
                updateStatus('disconnected', 'Error: ' + error.message);
                alert('Error en API REST: ' + error.message);
            }
        }
        
        // Actualizar estado visual
        function updateStatus(status, message) {
            statusIndicator.className = `status-indicator status-${status}`;
            statusIndicator.textContent = message;
            
            // Actualizar botones
            connectBtn.disabled = status === 'connecting' || status === 'connected';
            speakBtn.disabled = status !== 'connected';
            stopBtn.disabled = status !== 'playing';
            downloadDebugBtn.disabled = !lastAudioData;
        }
        
        // Manejar cambio de volumen
        function updateVolume() {
            currentVolume = parseFloat(volumeControl.value);
            volumeValue.textContent = Math.round(currentVolume * 100) + '%';
            console.log('üîä Volumen actualizado a:', currentVolume);
        }
        
        // Descargar √∫ltimo audio para debug
        function downloadLastAudio() {
            if (lastAudioData) {
                downloadAudioForDebug(lastAudioData);
            } else {
                alert('No hay audio disponible para descargar');
            }
        }
        
        // Conectar WebSocket
        function connectWebSocket() {
            updateStatus('connecting', 'Conectando...');
            
            // Verificar API key
            if (API_KEY === "tu-api-key") {
                alert('‚ö†Ô∏è Necesitas configurar tu API key de ElevenLabs antes de conectar');
                updateStatus('disconnected', 'API key requerida');
                return;
            }
            
            // Usar la misma configuraci√≥n que funciona en API REST
            const wsUrl = `wss://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}/stream-input?model_id=eleven_multilingual_v2`;
            console.log('üîó Conectando WebSocket a:', wsUrl);
            
            ws = new WebSocket(wsUrl);
            
            ws.onopen = function() {
                console.log('‚úÖ WebSocket conectado exitosamente');
                updateStatus('connected', 'Conectado');
                
                // Enviar configuraci√≥n inicial BOS (Beginning of Stream)
                const bosMessage = {
                    text: " ",
                    voice_settings: {
                        stability: 0.5,
                        similarity_boost: 0.5,
                        style: 0.0,
                        use_speaker_boost: true
                    },
                    generation_config: {
                        chunk_length_schedule: [120, 160, 250, 290]
                    },
                    xi_api_key: API_KEY
                };
                
                console.log('üì§ Enviando mensaje BOS:', bosMessage);
                ws.send(JSON.stringify(bosMessage));
            };
            
            ws.onmessage = async function(event) {
                try {
                    console.log('üì® Mensaje recibido del WebSocket');
                    
                    if (event.data instanceof Blob) {
                        console.log('üéµ Chunk de audio recibido (Blob), tama√±o:', event.data.size);
                        const audioData = await event.data.arrayBuffer();
                        console.log('üîä Convirtiendo a ArrayBuffer, tama√±o:', audioData.byteLength);
                        await playAudioChunk(audioData);
                    } else if (typeof event.data === 'string') {
                        try {
                            const response = JSON.parse(event.data);
                            console.log('üìã Respuesta del servidor:', response);
                            
                            if (response.audio) {
                                console.log('üéµ Audio en base64 recibido');
                                const binaryString = atob(response.audio);
                                const audioData = new Uint8Array(binaryString.length);
                                for (let i = 0; i < binaryString.length; i++) {
                                    audioData[i] = binaryString.charCodeAt(i);
                                }
                                await playAudioChunk(audioData.buffer);
                            }
                        } catch (parseError) {
                            console.log('üìù Mensaje de texto no JSON:', event.data);
                        }
                    }
                } catch (error) {
                    console.error('‚ùå Error procesando mensaje WebSocket:', error);
                }
            };
            
            ws.onclose = function(event) {
                console.log('üîå WebSocket cerrado:', event.code, event.reason);
                updateStatus('disconnected', 'Desconectado');
                ws = null;
            };
            
            ws.onerror = function(error) {
                console.error('‚ùå Error en WebSocket:', error);
                updateStatus('disconnected', 'Error de conexi√≥n');
                ws = null;
            };
        }
        
        // Reproducir chunk de audio
        async function playAudioChunk(audioData) {
            console.log('üéµ Intentando reproducir audio, tama√±o:', audioData.byteLength);
            
            // Guardar para debug
            lastAudioData = audioData;
            updateStatus('playing', 'Audio recibido...');
            
            try {
                // M√©todo 1: Web Audio API
                await initAudioContext();
                console.log('üì± AudioContext estado:', audioContext.state);
                
                if (audioData.byteLength > 0) {
                    const decodedAudio = await audioContext.decodeAudioData(audioData.slice(0));
                    console.log('‚úÖ Audio decodificado exitosamente, duraci√≥n:', decodedAudio.duration);
                    
                    // Crear fuente de audio
                    const source = audioContext.createBufferSource();
                    source.buffer = decodedAudio;
                    
                    // A√±adir ganancia para controlar volumen
                    const gainNode = audioContext.createGain();
                    gainNode.gain.value = currentVolume;
                    console.log('üîä Volumen configurado a:', currentVolume);
                    
                    source.connect(gainNode);
                    gainNode.connect(audioContext.destination);
                    
                    // Manejar eventos
                    source.onended = function() {
                        console.log('üîá Audio termin√≥ de reproducirse');
                        if (currentSource === source) {
                            updateStatus('connected', 'Conectado');
                            currentSource = null;
                        }
                    };
                    
                    // Reproducir
                    currentSource = source;
                    updateStatus('playing', 'Reproduciendo...');
                    source.start();
                    console.log('‚ñ∂Ô∏è Reproducci√≥n iniciada');
                    
                } else {
                    console.warn('‚ö†Ô∏è Audio data vac√≠o');
                    updateStatus('connected', 'Audio vac√≠o');
                }
                
            } catch (error) {
                console.error('‚ùå Error en Web Audio API:', error);
                // Intentar reproducci√≥n alternativa
                await playAudioFallback(audioData);
            }
        }
        
        // M√©todo alternativo de reproducci√≥n usando HTML5 Audio
        async function playAudioFallback(audioData) {
            console.log('üîÑ Intentando reproducci√≥n alternativa...');
            try {
                // Crear blob con diferentes tipos MIME
                const mimeTypes = ['audio/mpeg', 'audio/mp3', 'audio/wav', 'audio/ogg'];
                
                for (const mimeType of mimeTypes) {
                    try {
                        console.log(`üéµ Probando con tipo MIME: ${mimeType}`);
                        const blob = new Blob([audioData], { type: mimeType });
                        const audioUrl = URL.createObjectURL(blob);
                        const audio = new Audio(audioUrl);
                        
                        // Configurar volumen
                        audio.volume = currentVolume;
                        
                        // Promesa para manejar la carga y reproducci√≥n
                        await new Promise((resolve, reject) => {
                            let resolved = false;
                            
                            audio.oncanplaythrough = () => {
                                if (!resolved) {
                                    console.log(`‚úÖ Audio cargado con ${mimeType}, duraci√≥n:`, audio.duration);
                                    resolved = true;
                                    resolve();
                                }
                            };
                            
                            audio.onplay = () => {
                                console.log('‚ñ∂Ô∏è Reproducci√≥n HTML5 iniciada');
                                updateStatus('playing', 'Reproduciendo...');
                            };
                            
                            audio.onended = () => {
                                console.log('üîá Audio HTML5 termin√≥');
                                updateStatus('connected', 'Completado');
                                URL.revokeObjectURL(audioUrl);
                            };
                            
                            audio.onerror = (e) => {
                                console.error(`‚ùå Error con ${mimeType}:`, e);
                                URL.revokeObjectURL(audioUrl);
                                if (!resolved) {
                                    resolved = true;
                                    reject(e);
                                }
                            };
                            
                            audio.load();
                            
                            // Timeout como respaldo
                            setTimeout(() => {
                                if (!resolved) {
                                    console.log(`‚è∞ Timeout para ${mimeType}, intentando reproducir de todos modos`);
                                    resolved = true;
                                    resolve();
                                }
                            }, 2000);
                        });
                        
                        // Intentar reproducir
                        await audio.play();
                        console.log(`üéâ Reproducci√≥n exitosa con ${mimeType}`);
                        return; // Si llegamos aqu√≠, funcion√≥
                        
                    } catch (typeError) {
                        console.warn(`‚ö†Ô∏è Fall√≥ tipo ${mimeType}:`, typeError);
                        continue;
                    }
                }
                
                throw new Error('Ning√∫n tipo MIME funcion√≥');
                
            } catch (error) {
                console.error('‚ùå Error en reproducci√≥n alternativa:', error);
                updateStatus('connected', 'Error de audio');
                
                // √öltima opci√≥n: guardar como archivo para debug
                downloadAudioForDebug(audioData);
            }
        }
        
        // Funci√≥n para descargar audio para debug
        function downloadAudioForDebug(audioData) {
            try {
                const blob = new Blob([audioData], { type: 'audio/mpeg' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'debug_audio_' + Date.now() + '.mp3';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
                console.log('üíæ Audio guardado para debug');
                alert('Audio guardado para debug. Revisa tu carpeta de descargas.');
            } catch (error) {
                console.error('Error guardando audio para debug:', error);
            }
        }
        
        // Funci√≥n de prueba con respuesta AI
        function testAIResponse() {
            // Simular la respuesta que mencionaste
            const mockAIResponse = {
                "result": "Entiendo tu pregunta.  Veo que est√°s buscando saber qu√© pel√≠cula tiene a los personajes que aparecen en la imagen, pero lamentablemente no he podido procesar la imagen.  \\n\\nComo no tengo la imagen, no puedo decirte qu√© pel√≠cula es.  Si pudieras describir los personajes o darme m√°s detalles sobre la imagen, quiz√°s pueda ayudarte a encontrarla.  \\n\\nSi tu pregunta es sobre algo m√°s, no dudes en preguntar.  ¬°Estoy aqu√≠ para ayudarte!"
            };
            
            console.log('ü§ñ Procesando respuesta AI de prueba...');
            processAIResponse(mockAIResponse);
        }
        
        // Enviar texto para sintetizar (WebSocket mejorado)
        function speakText() {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                alert('WebSocket no est√° conectado. Usa "Conectar WebSocket" primero.');
                return;
            }
            
            let text = ttsText.value.trim();
            if (!text) {
                alert('Por favor, escribe algo de texto');
                return;
            }
            
            // Limpiar el texto antes de enviar
            text = cleanTextForTTS(text);
            console.log('üì§ Enviando texto limpio para sintetizar:', text);
            
            // Enviar texto al WebSocket (formato correcto para streaming)
            const textMessage = {
                text: text + " ",
                try_trigger_generation: true
            };
            
            console.log('üì® Mensaje de texto:', textMessage);
            ws.send(JSON.stringify(textMessage));
            
            // Enviar mensaje EOS (End of Stream) despu√©s de un breve delay
            setTimeout(() => {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    const eosMessage = {
                        text: ""
                    };
                    console.log('üì§ Enviando mensaje EOS');
                    ws.send(JSON.stringify(eosMessage));
                }
            }, 100);
            
            updateStatus('connecting', 'Generando audio...');
        }
        
        // Parar reproducci√≥n
        function stopAudio() {
            if (currentSource) {
                currentSource.stop();
                currentSource = null;
                updateStatus('connected', 'Conectado');
            }
        }
        
        // Event listeners
        connectBtn.addEventListener('click', connectWebSocket);
        speakBtn.addEventListener('click', speakText);
        stopBtn.addEventListener('click', stopAudio);
        testAudioBtn.addEventListener('click', testAudio);
        restApiBtn.addEventListener('click', useRestAPI);
        testAIBtn.addEventListener('click', testAIResponse);
        downloadDebugBtn.addEventListener('click', downloadLastAudio);
        volumeControl.addEventListener('input', updateVolume);
        
        // Inicializar estado
        updateStatus('disconnected', 'Desconectado');
        updateVolume(); // Inicializar display del volumen
        
        // Inicializar audio en la primera interacci√≥n del usuario
        document.addEventListener('click', function initOnFirstClick() {
            initAudioContext();
            document.removeEventListener('click', initOnFirstClick);
        }, { once: true });
    </script>
</body>
</html>
